# â™¾ï¸ My 45-Day DevOps Journey: Zero to Hero

Welcome to my documentation of the **Zero to Hero DevOps Course**. This repository is a living log of my transition into the world of DevOpsâ€”tracking daily progress, technical insights, and the cultural shifts required to master modern software delivery.

<details open>
<summary>ğŸš€ <b>Day 1: The Genesis â€“ Understanding the "Why" and "What" of DevOps</b></summary>
<br>

### The Narrative: Beyond the Textbook
In the traditional software world, delivery was a slow, fragmented process. Developers wrote code and "tossed it over the wall" to the Operations team. This resulted in silos, manual bottlenecks, and delivery cycles that took weeks or even months. 

**DevOps emerged as the solution.** It isnâ€™t just a set of tools; it is a **culture** and a **practice**. The goal is to increase an organizationâ€™s ability to deliver applications at high velocity without sacrificing quality.



### ğŸ—ï¸ The Four Pillars of DevOps
While many equate DevOps solely with CI/CD, it actually rests on four critical pillars that ensure a healthy delivery ecosystem:

1. **Automation ğŸ¤–**: Moving away from manual labor to repeatable, automated processes. If a task is performed twice, it should be automated.
2. **Quality âœ…**: Ensuring every piece of code is reliable. Speed is useless if the application is broken upon arrival.
3. **Monitoring & Observability ğŸ“‰**: You cannot improve what you cannot measure. Continuous monitoring ensures the system's health is always visible.
4. **Continuous Testing ğŸ§ª**: Testing is no longer a "final phase." It is integrated into every step of the lifecycle to catch bugs as early as possible.

> **The Professional Definition:** DevOps is a culture and process of improving application delivery by ensuring proper automation, maintained quality, continuous monitoring, and rigorous testing.

### ğŸ•°ï¸ The Evolution: Why We Need It
* **The Old World:** System Admins, Build & Release Engineers, and Server Admins worked in separate bubbles. A simple deployment could take 10+ days because of manual hand-offs and a lack of shared responsibility.
* **The New World:** DevOps breaks these silos. By integrating these roles into a unified culture, we reduce that 10-day cycle to hours or even minutes. This is how modern tech giants maintain their competitive edge.

### ğŸ¤ Professional Growth: The Art of the Introduction
A key part of Day 1 was learning how to position oneself in the industry. Whether coming from a System Admin, Developer, or Testing background, the secret to a great DevOps introduction is highlighting your **problem-solving mindset**.

Instead of just listing tools (like Jenkins or Docker), focus on how you implement the **Four Pillars** to solve business problems. Being authentic about your background and showing an eagerness to adapt to the "DevOps Culture" is what sets a candidate apart in an interview.

### ğŸ’¡ Key Takeaways
* DevOps is a **mindset shift**, not just a job title.
* The ultimate goal is **Velocity + Reliability**.
* Silos and manual processes are the primary enemies of efficiency.

---
</details>




<details open>
<summary>ğŸš€ <b>Day 2: SDLC & The Role of DevOps</b></summary>
<br>

### Bridging the SDLC Gap with DevOps
On Day 2, the focus shifted to the backbone of the IT industry: the **Software Development Life Cycle (SDLC)**. Understanding this lifecycle is non-negotiable, as it defines the standard process for designing, developing, and testing high-quality software.

#### ğŸ—ï¸ The 6 Phases of SDLC
1. **Planning & Requirement Gathering ğŸ“**: Gathering customer feedback to define the "What."
2. **Defining ğŸ“‘**: Creating the **Software Requirement Specification (SRS)**.
3. **Designing ğŸ¨**: Blueprints for architecture (HLD) and specific logic (LLD).
4. **Building (Developing) ğŸ’»**: Developers writing code and pushing to **Git**.
5. **Testing ğŸ§ª**: QA Engineers validating the code in staging environments.
6. **Deployment ğŸš€**: Promoting the code to production for the end user.


---

## ğŸ›ï¸ Phase 0: The Business of DevOps (Prerequisites)
Before writing code, I explored how software moves from a customer's idea to a DevOps engineer's task.

* **Organizational Awareness:** Understanding the roles of Product Managers, Architects, and the Scrum Team.
* **Agile Methodology:** Working in Sprints, attending Daily Stand-ups, and managing blockers.
* **The Jira Workflow:** How "Business Requirements" (BRD) become "Technical Tasks" via Epics and Stories.

ğŸ‘‰ **[Detailed Prerequisite Documentation](./Absolute%20Prerequisite%20for%20Learning%20DevOps.md)**

---

#### ğŸ› ï¸ The DevOps Battleground
A DevOps engineer acts as the "accelerant" for the SDLC. While we are aware of all phases, our primary focus is on **automating** the **Building, Testing, and Deployment** phases. 

By removing manual intervention, we ensure:
* **Efficiency:** Faster delivery cycles.
* **Reliability:** Reduced human error during deployment.
* **Agility:** Moving away from rigid models to fast-paced, iterative Sprints.

> **Key Takeaway:** SDLC is about *Quality*; DevOps is about *Quality at Speed*.

---
</details>

<details open>
<summary>ğŸš€ <b>Day 3: Virtual Machines & Virtualization</b></summary>
<br>

**Focus:** Moving from physical hardware to logical infrastructure.

* **The Shift:** Moving away from "Bare Metal" (physical servers) to **Virtual Machines (VMs)** to eliminate resource waste.
* **The Land Analogy:** Understanding how one physical server (the land) can host multiple isolated VMs (houses) without interference.
* **The Hypervisor:** Learning about the software (Type 1 & Type 2) that acts as the "Resource Traffic Controller" for CPU and RAM.
* **Cloud Mechanics:** How AWS and Azure use hypervisors in global Data Centers to provide EC2 instances on demand.



> **Key Takeaway:** Virtualization is the core engine of the Cloud. It provides the **Efficiency** and **Scaling** that DevOps requires.

ğŸ‘‰ **[Read Full Day 3 Documentation](./day3.md)**

---
</details>

<details>
<summary>ğŸš€ <b>Day 4: AWS & Azure â€“ Hands-on VM Creation</b></summary>
<br>

**Focus:** Moving from theory to practice by launching cloud infrastructure.

* **Manual vs. Automated:** Understanding that while the **AWS Console** and **Azure Portal** are great for learning, DevOps engineers use **APIs** and **CLI** for efficiency.
* **EC2 Instance Creation:** Successfully navigated the AWS lifecycle: Choosing an **AMI (Ubuntu)**, selecting **Free Tier (t2.micro)**, and generating **Key Pairs (.pem)** for secure access.
* **Automation Tools:** Brief introduction to **Infrastructure as Code (IaC)** tools like **Terraform, AWS CDK, and CloudFormation** that eliminate manual human error.
* **Security & Networking:** Learned that a request must be **Valid, Authenticated, and Authorized** before a Hypervisor provisions resources.



> **Key Takeaway:** A DevOps engineerâ€™s goal is **Efficiency**. If you have to create 100 servers, you write a script; you don't click the button 100 times.

ğŸ‘‰ **[Read Full Day 4 Documentation](./day4.md)**

---
</details>
<details>
<summary>ğŸ› ï¸ <b>Day 5: AWS CLI & SSH Mastery</b></summary>
<br>

**Focus:** Mastering the command line and secure remote access.

* **SSH Connectivity:** Learned how to log into EC2 instances using the terminal and the importance of setting correct permissions (`chmod 400`) on `.pem` keys.
* **AWS CLI Setup:** Configured local environments using `aws configure` to interact with AWS services without opening a browser.
* **Resource Management:** Practiced managing S3 buckets and EC2 instances directly through terminal commands.
* **Automation Teaser:** Explored how **Boto3 (Python)** and **CloudFormation** are used to automate resource creation at scale.

> **Key Takeaway:** Real DevOps work happens in the terminal. Mastering the CLI and SSH is the first step toward true automation.

ğŸ‘‰ **[Read Full Day 5 Documentation](./day5.md)**

---
</details>

<details>
<summary>ğŸ§ <b>Day 6: Linux & Shell Scripting Fundamentals</b></summary>
<br>

**Focus:** Understanding the Linux OS and mastering the terminal.

* **Linux Architecture:** Explored the relationship between **Hardware**, the **Kernel** (Heart of OS), and the **Shell** (Command Interpreter).
* **Navigation Mastery:** Learned essential commands for file management: `pwd`, `ls -ltr`, `cd`, `mkdir`, and `touch`.
* **System Monitoring:** Practiced checking server health using `top` (Task Manager), `free -m` (RAM), and `df -h` (Disk space).
* **File Editing:** Introduction to the **VI editor**â€”learning to switch between Command and Insert modes to edit configuration files.
* **Why Linux?** Discussed why Linux's security, speed, and open-source nature make it the standard for DevOps.

> **Key Takeaway:** You cannot be a DevOps Engineer without being comfortable in a Linux terminal. It is the foundation for Docker, Kubernetes, and Cloud.

ğŸ‘‰ **[Read Full Day 6 Documentation](./day6.md)**

---
</details>

---

## ğŸ“… Day 8: GitHub API Integration Project

Automated user access auditing for GitHub repositories using Shell Scripting and REST APIs. This project focuses on the intersection of automation, security, and data parsing.

### ğŸš€ Key Features
* **GitHub REST API:** Consumed live endpoints to fetch repository metadata.
* **Authentication:** Implemented secure API access using Personal Access Tokens (PAT) and environment variables.
* **JSON Parsing:** Utilized `jq` to filter complex nested data and extract specific collaborator information.
* **User Audit:** Created a script that identifies users with specific permissions (Read/Write) for security compliance.

### ğŸ› ï¸ Tech Stack
`Bash` | `GitHub API` | `Curl` | `JQ` | `Linux`



**[View Day 8 Project Details](./day8.md)**

---

---

## ğŸ“… Day 9: Git & GitHub Mastery

Mastered the core concepts of Version Control Systems (VCS) and the practical workflow of Git and GitHub, which are essential for collaboration in DevOps.



### ğŸš€ Key Features
* **Version Control Fundamentals:** Deep dive into why VCS is critical for code sharing and disaster recovery.
* **Architecture:** Compared **Centralized** (SVN) vs. **Distributed** (Git) systems to understand fault tolerance.
* **Git Internals:** Explored the local lifecycle of codeâ€”Moving files from the **Working Directory** to the **Staging Area** and finally to **Commits**.
* **GitHub Integration:** Learned how to bridge local development with cloud hosting using Remote repositories and **Forking**.

### ğŸ› ï¸ Tech Stack
`Git` | `GitHub` | `Version Control` | `Linux Terminal`



**[View Day 9 Project Details](./day9.md)**

---


---

## ğŸ“… Day 10: Git Branching Strategies

Focused on how enterprise-level organizations manage massive codebases using advanced Git branching workflows. This knowledge is essential for maintaining production stability while allowing for rapid feature development.



### ğŸš€ Key Features
* **Feature Branching:** Isolated development environments for new functionality to prevent breaking the main codebase.
* **Release Management:** Using dedicated Release branches to perform final testing and "freeze" code before production deployment.
* **Emergency Hotfixes:** Implementing the Hotfix workflow to patch critical production bugs without waiting for the next release cycle.
* **Industry Standards:** Analyzed the branching models used by **Kubernetes** and **Uber** to handle thousands of concurrent contributors.

### ğŸ› ï¸ Tech Stack
`Git` | `GitHub` | `SDLC` | `DevOps Workflows`



**[View Day 10 Project Details](./day10.md)**

---
---

## ğŸ“… Day 11: Git for DevOps - Real World Scenarios

Deep dived into the practical application of Git in a professional DevOps environment, focusing on automation, security, and advanced history management.



### ğŸš€ Key Features
* **Professional Workflow:** Mastered the `Add-Commit-Push` lifecycle and understood the internal role of the `.git` directory for tracking and security hooks.
* **Authentication Security:** Configured **SSH Key-based authentication** (`ssh-keygen`) to implement secure, passwordless communication between local machines and GitHub.
* **Complex Merging:** Analyzed the technical trade-offs between **Merge** and **Rebase**, focusing on how to maintain a clean linear history in large-scale enterprise projects.
* **Precision Operations:** Practiced **Cherry-picking** to isolate and apply specific commits across branches without performing a full merge.
* **Conflict Resolution:** Learned to manually resolve merge conflicts, a critical skill when multiple teams collaborate on the same microservice or configuration file.

### ğŸ› ï¸ Tech Stack
`Git` | `GitHub` | `SSH` | `Linux CLI` | `Version Control`



**[View Full Day 11 Project Details](./day11.md)**

---
---

## ğŸ“… Day 11: Git for DevOps â€” Real-World Scenarios

Todayâ€™s session focused on professional Git workflows, moving beyond simple commands to understand how DevOps engineers manage collaboration, security, and complex code histories.



### ğŸš€ Key Takeaways
* **Inside the `.git` Directory:** Explored the internal structure of Git and how **Hooks** (like pre-commit) can be used to scan for secrets or enforce coding standards.
* **Secure Authentication:** Configured **SSH Key-based authentication** (`ssh-keygen`) to implement secure, passwordless communication between local environments and GitHub.
* **Strategic Branching:** Learned to use feature branches to isolate massive changes (e.g., a "House Services" feature) without disrupting the production-ready `main` branch.
* **Precision Operations:** Mastered **Cherry-picking** to pull specific, high-priority commits (like bug fixes) into a branch without performing a full merge.
* **Merge vs. Rebase:** Deep dive into the trade-offs between preserving an exact history (**Merge**) versus maintaining a clean, linear project timeline (**Rebase**).
* **Conflict Resolution:** Learned the manual process of resolving merge conflicts that occur when multiple teams edit the same lines of code.



### ğŸ› ï¸ Tech Stack & Essential Commands
`Git` | `GitHub` | `SSH` | `CLI`

* `git checkout -b <branch>` â€” Create and switch to a new feature branch.
* `git cherry-pick <commit-id>` â€” Apply a specific change from another branch.
* `git rebase <branch>` â€” Re-write history for a cleaner timeline.
* `git remote add origin <url>` â€” Connect a local repository to the cloud.

**[View Full Day 11 Project Details](./day11.md)**

---
---

## ğŸ“… Day 12: Deploy and Expose Your First App to AWS

Todayâ€™s session was a hands-on live project featuring Kunal Verma. We moved from local development to the cloud by deploying a real-time NodeJS application (integrated with Stripe) onto an AWS EC2 instance and making it accessible to the world.

### ğŸš€ Key Takeaways
* **Local Testing First:** Cloned the repository and tested the NodeJS app locally to ensure all dependencies and environment variables (`.env`) were working correctly.
* **AWS IAM Best Practices:** Instead of using the Root account, we created an **IAM User** with specific permissions. This is a critical security standard in DevOps to minimize risk.
* **Provisioning EC2:** Launched an **Ubuntu 22.04 LTS** instance on AWS, selecting the `t2.micro` instance type to stay within the Free Tier.
* **Server Configuration:** Connected via **SSH** and manually bootstrapped the remote server by installing:
    * **Git**: To pull the source code.
    * **NodeJS & NPM**: To build and run the application environment.
* **Environment Security:** Used **Vim** to securely create a hidden `.env` file on the server to store Stripe API keys without exposing them in the version control.
* **Networking & Security Groups:** The most crucial stepâ€”learned how to edit **Inbound Rules** to open **Port 3000**, allowing the public internet to access the application hosted on the EC2 instance.

### ğŸ› ï¸ Tech Stack & Essential Commands
`AWS EC2` | `IAM` | `NodeJS` | `Linux` | `Stripe API`

* `ssh -i <key.pem> ubuntu@<public-ip>` â€” Securely connect to the AWS instance.
* `sudo apt update && sudo apt install nodejs npm` â€” Prepare the server environment.
* `touch .env && vim .env` â€” Create and edit hidden configuration files.
* **Security Group Config**: Added a Custom TCP rule for **Port 3000** with source `0.0.0.0/0`.

**[View Day 12 Video Tutorial](http://www.youtube.com/watch?v=NLmF64KdLN0)**

---
### ğŸ—“ï¸ Day 13: Top 15 AWS Services for DevOps

On Day 13, I shifted from manual deployment to a strategic overview of the **AWS Cloud Ecosystem**. With over 200+ services available, the focus was on identifying the core tools that drive **Automation, Security, and Efficiency** in a modern DevOps pipeline.



**Key Highlights:**
* **Infrastructure & Networking:** Explored the foundational roles of **EC2** (Compute), **VPC** (Networking), and **Lambda** (Serverless).
* **Native CI/CD:** Studied the AWS Developer stackâ€”**CodePipeline**, **CodeBuild**, and **CodeDeploy**â€”as alternatives to external tools like Jenkins.
* **Security & Governance:** Deep-dived into **IAM** for access control, **AWS Config** for compliance, and **CloudTrail** for API auditing.
* **Containers:** Analyzed the differences between **EKS** (Managed Kubernetes) and **ECS** (AWS Proprietary) for container orchestration.
* **Monitoring:** Leveraged **CloudWatch** for observability and **Billing/Cost Management** for infrastructure optimization.

> **Crucial Takeaway:** DevOps is about using the right tool for the job. Mastering these 15 services allows for building resilient, "Well-Architected" cloud environments.

---

### ğŸ› ï¸ Day 14: Configuration Management & Ansible Theory

This session introduces the concept of **Configuration Management** and why it is critical for maintaining consistency across a fleet of servers. We explore **Ansible** as the primary tool for solving manual overhead.

**Key Learning Objectives:**
* **Manual vs. Automated Management:** Why logging into 100 servers individually is a security and operational risk.
* **The Agentless Advantage:** Understanding how Ansible uses SSH to manage nodes without requiring client-side software installation.
* **Idempotency:** Learning how Ansible ensures a task is only performed if the system is not already in the desired state.
* **Ansible Architecture:** Introduction to Control Nodes, Managed Nodes, and the Inventory system.



---

### ğŸ“œ Day 15: Ansible Playbooks & Practical Implementation

In this session, we move from theory to hands-on automation by learning how to write and execute **Ansible Playbooks** to manage infrastructure at scale.

**Key Learning Objectives:**
* **YAML for Automation:** Mastering the syntax used to write declarative Ansible Playbooks.
* **Inventory Management:** Organizing servers into groups (e.g., [web_servers], [db_servers]) for targeted automation.
* **Tasks & Modules:** Using built-in modules like `apt`, `yum`, `copy`, and `service` to perform complex operations.
* **Practical Workflow:** Setting up passwordless SSH authentication and executing playbooks using the `ansible-playbook` command.

### â˜ï¸ Day 16: Infrastructure as Code (IaC) & Terraform Foundations

This session explores the theoretical shift from manual infrastructure configuration to automated, code-based management. We dive deep into why **Terraform** has become the industry standard for modern DevOps.

**Key Learning Objectives:**
* **The Problem with Platform Lock-in:** Understanding why native tools like AWS CloudFormation (CFT) or Azure Resource Manager (ARM) create challenges in hybrid-cloud environments.
* **The Terraform Solution:** How a single, provider-agnostic tool can manage multiple cloud platforms (AWS, Azure, GCP) and on-premise systems.
* **API as Code:** A deep dive into how Terraform translates HCL (HashiCorp Configuration Language) into programmatic API calls to talk to cloud providers.
* **Hybrid & Multi-Cloud Strategy:** Why organizations are moving toward architectures that utilize the best services from different clouds simultaneously.



---
**Detailed Documentation:** [day16.md](./day16.md)

## ğŸš€ Day 17: Terraform Production-Grade Management

Day 17 marked the transition from basic Terraform usage to professional, team-oriented infrastructure management. The focus was on ensuring state security, collaboration, and code reusability.

### ğŸ”‘ Key Learning Objectives

* **Remote State Management:** Migrated the `terraform.tfstate` from local storage to **Amazon S3** for centralized access and durability through versioning.
* **State Locking:** Implemented **DynamoDB** to handle state locking. This prevents race conditions and state corruption when multiple engineers work on the same infrastructure simultaneously.
* **Modular Architecture:** Explored **Terraform Modules** to package resource configurations into reusable "Lego blocks," enforcing DRY (Don't Repeat Yourself) principles and organizational standards.
* **Professional Workflow:** Mastered the clean separation of concerns using `variables.tf`, `outputs.tf`, and `backend.tf` to keep projects manageable and scalable.

### ğŸ› ï¸ Technical Concepts Covered
* **Backend Configuration:** Setting up S3 and DynamoDB within the `terraform` block.
* **Lifecycle Management:** Deep dive into `init`, `plan`, `apply`, and `destroy` in a remote context.
* **State Drift:** Understanding the limitations of Terraform when manual changes occur in the AWS Console.
* **Multi-Cloud Strategy:** Leveraging different Providers (AWS, Azure, GCP) under the same HCL syntax.

### âœ… Accomplishments
- [x] Secured the infrastructure "Source of Truth" using an S3 Remote Backend.
- [x] Prevented concurrent execution conflicts with DynamoDB State Locking.
- [x] Created reusable resource templates using Terraform Modules.
- [x] Standardized project structure for better team collaboration.

**Detailed Documentation:** [day17.md](./day17.md)
